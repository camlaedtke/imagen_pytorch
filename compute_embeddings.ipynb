{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b394a1",
   "metadata": {},
   "source": [
    "# Computation of caption text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fba3742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import random\n",
    "import braceexpand\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import webdataset as wds\n",
    "from imagen_pytorch.t5 import t5_encode_text\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6efab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_batch(text):\n",
    "    text_embeds = t5_encode_text(text, name=\"google/t5-v1_1-xl\", return_attn_mask=False)\n",
    "    text_embeds = text_embeds.cpu()\n",
    "    emb_batch = []\n",
    "    for tensor in text_embeds:\n",
    "        ix, iy = tensor.nonzero(as_tuple=True)\n",
    "        tensor_nonzero = tensor[None, 0:max(ix)+1:]\n",
    "        emb_batch.append(tensor_nonzero)\n",
    "    return emb_batch\n",
    "\n",
    "\n",
    "def batch_augment_wds(input_shard, output_shard, batch_size):\n",
    "    start = time()\n",
    "    count = get_count(input_shard)\n",
    "    input_shard = \"file:\"+input_shard\n",
    "    \n",
    "    src = wds.DataPipeline(\n",
    "        wds.SimpleShardList(input_shard),\n",
    "        wds.tarfile_to_samples(),\n",
    "        wds.decode(\"pil\"),\n",
    "        wds.to_tuple(\"__key__\", \"jpg;png\", \"txt\")\n",
    "    )\n",
    "    \n",
    "    idx = 1\n",
    "    batch_idx = 0\n",
    "    keys=[]; imgs=[]; caps=[]; embs=[]\n",
    "    for key, img, cap in tqdm(src, total=count, desc=f\"Extracting {input_shard}\"):\n",
    "        keys.append(key)\n",
    "        imgs.append(img)\n",
    "        caps.append(cap)\n",
    "        \n",
    "        if ((idx%batch_size) == 0 and idx != 1) or idx == count:\n",
    "            emb_batch = get_emb_batch(caps[batch_size*batch_idx:])\n",
    "            for emb in emb_batch:\n",
    "                embs.append(emb)\n",
    "            batch_idx += 1\n",
    "        idx += 1\n",
    "                \n",
    "    dst = wds.TarWriter(output_shard)\n",
    "    for key, img, cap, emb in tqdm(zip(keys, imgs, caps, embs), total=count, desc=f\"Writing {output_shard}\"):\n",
    "        dst.write({\n",
    "            \"__key__\":key, \n",
    "            \"png\":img, \n",
    "            \"txt\":cap, \n",
    "            \"emb.pyd\":emb\n",
    "        })\n",
    "        \n",
    "    end = time()\n",
    "    print(f\"Finished - {end-start:.0f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b3add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_tensor(text):\n",
    "    text_embeds = t5_encode_text([text], name=\"google/t5-v1_1-xl\", return_attn_mask=False)\n",
    "    return text_embeds.cpu()\n",
    "\n",
    "\n",
    "def get_count(input_file):\n",
    "    stats_file = input_file[:-4] + \"_stats.json\"\n",
    "    f = open(stats_file)\n",
    "    stats = json.load(f)\n",
    "    f.close()\n",
    "    count = stats[\"successes\"]\n",
    "    return count\n",
    "\n",
    "\n",
    "def shuffle_augment_wds(input, output):\n",
    "    \"\"\"Takes ~300s for each .tar file\"\"\"\n",
    "    start = time()\n",
    "    count = get_count(input)\n",
    "    input = \"file:\"+input\n",
    "    src = wds.DataPipeline(\n",
    "        wds.SimpleShardList(input),\n",
    "        wds.tarfile_to_samples(),\n",
    "        wds.decode(\"pil\"),\n",
    "        wds.to_tuple(\"__key__\", \"jpg;png\", \"txt\", \"txt\"),\n",
    "        wds.map_tuple(None, None, None, get_emb_tensor)\n",
    "    )\n",
    "    \n",
    "    samples = []\n",
    "    for key, img, cap, emb in tqdm(src, total=count, desc=f\"Extracting {input}\"):\n",
    "        samples.append([key, img, cap, emb])\n",
    "    random.shuffle(samples)    \n",
    "    \n",
    "    dst = wds.TarWriter(output)\n",
    "    for sample in tqdm(samples, total=count, desc=f\"Writing {output}\"):\n",
    "        dst.write({\n",
    "            \"__key__\":sample[0], \n",
    "            \"png\":sample[1], \n",
    "            \"txt\":sample[2], \n",
    "            \"emb.pyd\":sample[3]\n",
    "        })\n",
    "    end = time()\n",
    "    print(f\"Finished - {end-start:.0f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ffa0280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shards = braceexpand.braceexpand(\"cc12m_original/{01095..01242}.tar\")\n",
    "# output_shards = braceexpand.braceexpand(\"file:E:/datasets/cc12m_w_embeds/{01095..01242}.tar\")\n",
    "# for input_shard, output_shard in zip(input_shards, output_shards):\n",
    "#     batch_augment_wds(input_shard, output_shard, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c788d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting file:cc12m_original/01229.tar: 100%|██████████| 8461/8461 [03:46<00:00, 37.37it/s]\n",
      "Writing file:E:/datasets/cc12m_w_embeds/01229.tar: 100%|██████████| 8461/8461 [01:20<00:00, 105.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished - 307s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting file:cc12m_original/01230.tar: 100%|██████████| 8536/8536 [03:21<00:00, 42.32it/s]\n",
      "Writing file:E:/datasets/cc12m_w_embeds/01230.tar: 100%|██████████| 8536/8536 [01:24<00:00, 100.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished - 286s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting file:cc12m_original/01231.tar: 100%|██████████| 8542/8542 [03:21<00:00, 42.38it/s]\n",
      "Writing file:E:/datasets/cc12m_w_embeds/01231.tar: 100%|██████████| 8542/8542 [01:27<00:00, 97.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished - 289s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting file:cc12m_original/01232.tar: 100%|██████████| 8437/8437 [03:19<00:00, 42.25it/s]\n",
      "Writing file:E:/datasets/cc12m_w_embeds/01232.tar: 100%|██████████| 8437/8437 [01:25<00:00, 98.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished - 285s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting file:cc12m_original/01233.tar: 100%|██████████| 8476/8476 [03:19<00:00, 42.45it/s]\n",
      "Writing file:E:/datasets/cc12m_w_embeds/01233.tar: 100%|██████████| 8476/8476 [01:27<00:00, 97.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished - 287s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting file:cc12m_original/01234.tar: 100%|██████████| 8471/8471 [03:20<00:00, 42.20it/s]\n",
      "Writing file:E:/datasets/cc12m_w_embeds/01234.tar: 100%|██████████| 8471/8471 [01:26<00:00, 98.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished - 287s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting file:cc12m_original/01235.tar: 100%|██████████| 8607/8607 [03:23<00:00, 42.33it/s]\n",
      "Writing file:E:/datasets/cc12m_w_embeds/01235.tar: 100%|██████████| 8607/8607 [01:28<00:00, 97.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished - 292s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting file:cc12m_original/01236.tar: 100%|██████████| 8495/8495 [03:19<00:00, 42.52it/s]\n",
      "Writing file:E:/datasets/cc12m_w_embeds/01236.tar: 100%|██████████| 8495/8495 [01:27<00:00, 97.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished - 287s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting file:cc12m_original/01237.tar: 100%|██████████| 8489/8489 [03:20<00:00, 42.27it/s]\n",
      "Writing file:E:/datasets/cc12m_w_embeds/01237.tar: 100%|██████████| 8489/8489 [01:27<00:00, 96.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished - 288s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting file:cc12m_original/01238.tar: 100%|██████████| 8543/8543 [03:21<00:00, 42.48it/s]\n",
      "Writing file:E:/datasets/cc12m_w_embeds/01238.tar: 100%|██████████| 8543/8543 [01:28<00:00, 96.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished - 290s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting file:cc12m_original/01239.tar: 100%|██████████| 8541/8541 [03:22<00:00, 42.25it/s]\n",
      "Writing file:E:/datasets/cc12m_w_embeds/01239.tar: 100%|██████████| 8541/8541 [01:29<00:00, 95.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished - 292s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting file:cc12m_original/01240.tar: 100%|██████████| 8479/8479 [03:19<00:00, 42.54it/s]\n",
      "Writing file:E:/datasets/cc12m_w_embeds/01240.tar: 100%|██████████| 8479/8479 [01:28<00:00, 95.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished - 288s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting file:cc12m_original/01241.tar: 100%|██████████| 8485/8485 [03:20<00:00, 42.24it/s]\n",
      "Writing file:E:/datasets/cc12m_w_embeds/01241.tar: 100%|██████████| 8485/8485 [01:28<00:00, 96.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished - 289s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting file:cc12m_original/01242.tar: 100%|██████████| 2869/2869 [01:07<00:00, 42.58it/s]\n",
      "Writing file:E:/datasets/cc12m_w_embeds/01242.tar: 100%|██████████| 2869/2869 [00:27<00:00, 105.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished - 95s\n"
     ]
    }
   ],
   "source": [
    "input_shards = braceexpand.braceexpand(\"cc12m_original/{01229..01242}.tar\")\n",
    "output_shards = braceexpand.braceexpand(\"file:E:/datasets/cc12m_w_embeds/{01229..01242}.tar\")\n",
    "for input_shard,  output_shard in zip(input_shards, output_shards):\n",
    "    shuffle_augment_wds(input=input_shard, output=output_shard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
