dataset:
  dataset_name: "cc12m"
  dataset_path: "file:E:/datasets/cc12m_w_embeds/{00000..01242}.tar" 
  image_size: 256
  shuffle_size: 20000
  shuffle_initial: 10000
  shard_shuffle: True
  num_images: 10554521
  num_workers: 1
  prefetch_factor: 1
  pin_memory: True
  drop_last: True
  precomputed_embeddings: True
train:
  epochs: 1
  batch_size: 120
  unet_number: 2
  unet1_max_batch_size: 24
  unet2_max_batch_size: 12
  load_checkpoint: True
  load_checkpoint_path: "./checkpoint/imagen_small_checkpoint.pt"
  checkpoint_path: "./checkpoint/imagen_small_checkpoint.pt"
  checkpoint_rate: 2000
  checkpoint_strict: False
  checkpoint_model_only: True
  image_non_blocking: True
  embedding_non_blocking: False
  cudnn_benchmark: True
  use_ema: True
  lr: 0.00003
  eps: 0.00000001
  beta1: 0.9
  beta2: 0.99
  max_grad_norm: None
  amp: True
  group_wd_params: True
  warmup_steps: None
  cosine_decay_max_steps: None
  cond_scale: 5
  sample_texts: ['dog','cheeseburger','blue car','red flowers in a white vase','a puppy looking anxiously at a giant donut on the table', 'lizard running across the desert on two feet']
model:
  text_encoder_name: "google/t5-v1_1-xl"
  image_sizes: [64, 256]
  cond_drop_prob: 0.1
  timesteps: 1000
  unet1:
    dim: 128
    cond_dim: 512
    dim_mults: [1, 2, 3, 4]
    num_resnet_blocks: 3
    layer_attns: [False, True, True, True]
    layer_cross_attns: [False, True, True, True]
    attn_heads: 8
    ff_mult: 2
    dropout: 0.1
    memory_efficient: False
    cosine_sim_attn: False
    use_linear_attn: False
  unet2:
    dim: 64
    cond_dim: 512
    dim_mults: [1, 2, 4, 8]
    num_resnet_blocks: [2, 4, 8, 8]
    layer_attns: [False, False, False, True]
    layer_cross_attns: [False, False, False, True]
    attn_heads: 8
    ff_mult: 2
    dropout: 0.1
    memory_efficient: True
    cosine_sim_attn: False
    use_linear_attn: False