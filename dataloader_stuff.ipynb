{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03656db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T, utils\n",
    "from torch.utils.data import DataLoader\n",
    "from imagen_pytorch.t5 import t5_encode_text\n",
    "from utils.data_utils import CocoDataset\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6afc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = yaml.safe_load(Path(\"configs/imagen-config.yaml\").read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df873707",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = CocoDataset(cfg)\n",
    "# dl = get_coco_dataloader(cfg, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a77c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, text = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5520699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_embeds, text_masks = ds.get_embed_tensor(ds.captions[2])\n",
    "# print(text_embeds.cpu().numpy().shape, text_masks.cpu().numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b987aed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_dataloader = DataLoader(\n",
    "    dataset = ds, \n",
    "    batch_size = 8, # cfg[\"train\"][\"batch_size\"], \n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    num_workers = 0,\n",
    "    # prefetch_factor = 8,\n",
    "    # pin_memory = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e00cca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " step 0\n",
      "torch.Size([8, 3, 256, 256]) ('A man stands on top of a mountain while skiing.', 'A man is standinb by a grill in a kitchen with a stack of plates near him.', 'A herd of horses standing on a prairie eating grass. ', 'Two men on a tennis court shaking hands.', 'A large team of Japanese kite enthusiasts haul a giant square kite into the sky. ', 'A bench next to a city street filled with cars with their lights on. ', 'A cute girl sliced freshly baked pizza on a black table.', 'A group of people sitting around a wooden table.')\n",
      "\n",
      " step 1\n",
      "torch.Size([8, 3, 256, 256]) ('A woman talks on a cell phone next to a pool.', 'A single zebra standing on a dirt road.', 'A couple poses for a photo besides a tree.', 'A jet is towed down the tarmac on a dreary gray day.', 'a taxi cab a police car a some buildings a street and some people', 'Some big cows grazing on some hays in the middle of a field.', 'a close up of a plate of food with pizza', 'A man exiting the ocean with his surfboard in hand')\n",
      "\n",
      " step 2\n",
      "torch.Size([8, 3, 256, 256]) ('A laptop with an odd assortment of recording tools on top of it. ', 'a tennis player holding a racket on the court', 'A toasted sandwich that has vegetables and meat on it.', 'A brown bowl of bananas on a wood counter.', 'Colorful luggage sits together next to other pieces.', 'A view of a bunch of passengers on a mass transit line.', 'A man wearing a hat and a black tie.', 'there is a small dog that is looking threw the glass')\n",
      "\n",
      " step 3\n",
      "torch.Size([8, 3, 256, 256]) ('Two zebras standing near some rocks in a field.', 'a man is doing a trick on a skateboard', 'A man and his son fly kits in a field as a crowd watches.', 'A pair of people on skis go up a hill.', 'A man standing underneath a marathon sign in the grass', 'A toilet is outside in a wooded area. ', 'A parked train inside an empty train station.', 'A bus crosses through the middle of a road')\n",
      "\n",
      " step 4\n",
      "torch.Size([8, 3, 256, 256]) ('A beautiful landscape filled with trees, shrubs and flowers. ', 'There is a giraffe standing next to a building', 'Two people coming down a mountain, one is skiing and the other is on a sled.', 'A white sink under a bathroom mirror with a bottle of beer on it.', 'a silver truck a street a person and buildings', 'many desserts sitting on a plate with two drinks on a tray', 'a horse pulling a carriage down the road ', 'A person swings their tennis racket on a court. ')\n",
      "\n",
      " step 5\n",
      "torch.Size([8, 3, 256, 256]) ('Man on surfboard surfing down a large wave.', 'Two elephants from side standing one in front of another in an outdoor natural enclosure with rocks, dirt and trees, and a group of people looking at them in the distance from other side of a wall.', 'a black cat seated on the edge of a neatly made bed ', 'A variety of different foods are on the table for your choosing.', 'A horse drawn carriage riding across a snow covered field.', 'A line of people riding dirt bikes during a dirt bike race.', 'A herd of elephants standing next to a river.', 'Three double decker busses take on passengers at a station.')\n",
      "\n",
      " step 6\n",
      "torch.Size([8, 3, 256, 256]) ('A vase with flower and apples on the table', 'A woman in a red shirt and a man in a black shirt playing a videogame. ', 'A kitchen with a stove and sink under some windows.', 'A woman posing for a picture in a kitchen.', 'A man holds a knife close to his face while leaning over a sink. ', 'The man is on the tennis court playing a game. ', 'A group of men sitting on two benches in a court yard area.', 'A woman is kneeling down to milk a cow.')\n",
      "\n",
      " step 7\n",
      "torch.Size([8, 3, 256, 256]) ('The Sun Valley Market on the corner of 10th Ave and Irving.', 'Three black steers face the camera in their paddock.', 'A boat in the water on a cloudy day.', 'A floor urinal with flushing pedals on it.', 'A black cat sitting in front of a desktop computer monitor.', 'A white plate full of broccoli with a fork on it. ', 'Tow men playing tennis on a hard surface court with people in the stands watching.', 'A woman on the back swing of a tennis shot')\n",
      "\n",
      " step 8\n",
      "torch.Size([8, 3, 256, 256]) ('A photo taken looking over the river at Big Ben.', 'Some empty canoes sitting on a green river.', 'A bunch of fruits and vegetables on a table.', 'A dog that is looking at a can of food.', 'A professional baseball pitcher pitching to home plate.', 'A cat sleeping on top of a computer on a table.', 'A picture of cooking pans full of sausage in someones kitchen. ', 'Some cars are going down the street in the city.')\n",
      "\n",
      " step 9\n",
      "torch.Size([8, 3, 256, 256]) ('A counter topped with lots of ripe and unripe bananas.', 'A man on a surf board riding a small wave.', 'A hand holding a sausage dog with sauerkraut and napkins.', 'some street signs in a foreign language with a person driving on a motorcycle', 'A train traveling through countryside surrounded by forest.', 'This is an old-fashioned kitchen, complete with many period tools.', 'A man is cutting a cake to celebrate hsi reelectio,', 'a close up ofa person eating a hot dog ')\n",
      "\n",
      " step 10\n",
      "torch.Size([8, 3, 256, 256]) ('Girl playing with a bean bag chair near a Christmas tree.', 'A man with a goatee and glasses standing in front of the camera.', 'Surfer catching a wave and going vertical at the break.', 'A European city center where a train passes a turreted building.', 'A table with a cate fashioned to look like a desk and laptop.', 'a ball player running for base after hitting the ball', 'Two plates of food sitting on top of a table.', 'A couple of people in a room with a Frisbee.')\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(coco_dataloader):\n",
    "    print()\n",
    "    print(f\"\\r step {step}\", end='')\n",
    "    print()\n",
    "    images, texts = batch\n",
    "    # print(texts)\n",
    "    print(images.shape, texts)\n",
    "    if step == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fcace5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058e27eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
