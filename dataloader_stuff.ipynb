{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03656db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T, utils\n",
    "from imagen_pytorch.t5 import t5_encode_text\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e1ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_tensor(cfg, targets, device):\n",
    "    text_embeds, text_masks = t5_encode_text(targets, name = cfg[\"model\"][\"text_encoder_name\"])\n",
    "    text_embeds, text_masks = map(lambda t: t.to(device), (text_embeds, text_masks))\n",
    "    return text_embeds, text_masks\n",
    "\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "\n",
    "def cycle(dl):\n",
    "    while True:\n",
    "        for data in dl:\n",
    "            yield data\n",
    "\n",
    "            \n",
    "def convert_image_to(img_type, image):\n",
    "    if image.mode != img_type:\n",
    "        return image.convert(img_type)\n",
    "    return image\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        cfg,\n",
    "        exts = ['jpg','jpeg','png','tiff'], \n",
    "        convert_image_to_type = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.captions_per_img = cfg[\"dataset\"][\"captions_per_image\"]\n",
    "        self.info_df = pd.read_pickle(cfg[\"dataset\"][\"info_file\"])\n",
    "        self.image_size = cfg[\"dataset\"][\"image_size\"]\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        \n",
    "        self.image_paths = self.info_df[\"file_path\"].values.tolist()\n",
    "        self.captions = self.info_df[\"caption\"].values.tolist()\n",
    "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "        convert_fn = partial(\n",
    "            convert_image_to, \n",
    "            convert_image_to_type\n",
    "        ) if exists(convert_image_to_type) else nn.Identity()\n",
    "\n",
    "        self.transform = T.Compose([\n",
    "            T.Lambda(convert_fn),\n",
    "            T.Resize(self.image_size),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.CenterCrop(self.image_size),\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "        \n",
    "    \n",
    "    def get_embed_tensor(self, caption):\n",
    "        text_embeds, text_masks = t5_encode_text(caption, name=self.cfg[\"model\"][\"text_encoder_name\"])\n",
    "        text_embeds, text_masks = map(lambda t: t.to(self.device), (text_embeds, text_masks))\n",
    "        return text_embeds, text_masks\n",
    "    \n",
    "    \n",
    "    def compute_embeddings():\n",
    "        self.info_df[\"text_embeds\"] = None\n",
    "        self.info_df[\"text_masks\"] = None\n",
    "        \n",
    "        for i in range(0, len(self.captions)):\n",
    "            print(f\"\\r computing {i+1}/{len(self.captions)}\", end='')\n",
    "            text_embeds, text_masks = self.get_embed_tensor(self.captions[i])\n",
    "            self.info_df.loc[i, \"text_embeds\"] = text_embeds\n",
    "            self.info_df.loc[i, \"text_masks\"] = text_masks\n",
    "            \n",
    "        self.info_df.to_pickle(self.cfg[\"dataset\"][\"info_file\"])\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Modify to return tuple ('images', 'text_embeds', 'text_masks')\"\"\"\n",
    "        path = self.image_paths[index]\n",
    "        img = self.transform(Image.open(path))\n",
    "        \n",
    "        caption = self.captions[index][random.randint(0, self.captions_per_img-1)]\n",
    "        text_embed, text_mask = self.get_embed_tensor(caption)\n",
    "        return img, text_embed, text_mask\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_coco_dataloader(\n",
    "    config, \n",
    "    *, \n",
    "    batch_size,\n",
    "    shuffle = True,\n",
    "    cycle_dl = False,\n",
    "    pin_memory = True\n",
    "):\n",
    "    ds = Dataset(config)\n",
    "    dl = data.DataLoader(\n",
    "        ds, \n",
    "        batch_size = batch_size, \n",
    "        shuffle = shuffle, \n",
    "        pin_memory = pin_memory\n",
    "    )\n",
    "\n",
    "    if cycle_dl:\n",
    "        dl = cycle(dl)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6afc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = yaml.safe_load(Path(\"configs/imagen-config.yaml\").read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df873707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = Dataset(cfg)\n",
    "# dl = get_coco_dataloader(cfg, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8141ed15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
