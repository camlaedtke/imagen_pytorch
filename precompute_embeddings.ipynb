{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6735c46",
   "metadata": {},
   "source": [
    "Steps in loop\n",
    "- Get image file name\n",
    "- Get associated text (or texts)\n",
    "- Compute embedding\n",
    "- Save embedding to new file embeddings folder\n",
    "- Make dataset class to handle the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from imagen_pytorch.t5 import t5_encode_text, DEFAULT_T5_NAME\n",
    "from typing import Any, Callable, Optional, Tuple, List\n",
    "from PIL import Image\n",
    "import itertools\n",
    "\n",
    "import torchvision\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb5be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_tensor(targets):\n",
    "    text_embeds, text_masks = t5_encode_text(targets, name = TEXT_ENCODER_NAME)\n",
    "    text_embeds = text_embeds.cpu().numpy()\n",
    "    text_masks = text_masks.cpu().numpy()\n",
    "    # text_embeds, text_masks = map(lambda t: t.to('cuda:0'), (text_embeds, text_masks))\n",
    "    return text_embeds, text_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4940434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"coco\\\\images\\\\train2014\",\n",
    "train_annFile = \"coco\\\\annotations\\\\captions_train2014.json\"\n",
    "valid_annFile = \"coco\\\\annotations\\\\captions_val2014.json\"\n",
    "train_embed_dir = \"coco\\\\embeddings\\\\train2014\\\\\"\n",
    "valid_embed_dir = \"coco\\\\embeddings\\\\val2014\\\\\"\n",
    "TEXT_ENCODER_NAME = \"t5-large\"\n",
    "\n",
    "coco = COCO(train_annFile)\n",
    "ids = list(sorted(coco.imgs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f088a60b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_one(id_):\n",
    "    path = coco.loadImgs(id_)[0][\"file_name\"]\n",
    "    captions = coco.loadAnns(coco.getAnnIds(id_))\n",
    "    caption = captions[0]['caption']\n",
    "    text_embed, text_mask = get_emb_tensor(caption)\n",
    "    return path, caption, text_embed, text_mask\n",
    "\n",
    "\n",
    "def get_path_caption_lists():\n",
    "    img_paths = []\n",
    "    img_captions = []\n",
    "    for id_ in ids:\n",
    "        path = coco.loadImgs(id_)[0][\"file_name\"]\n",
    "        targets = coco.loadAnns(coco.getAnnIds(id_))\n",
    "        captions = [tar['caption'] for tar in targets]\n",
    "        img_paths.append(path)\n",
    "        img_captions.append(captions[0])\n",
    "    return img_paths, img_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f899694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8857b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(img_paths, img_captions, batch_size = 256):\n",
    "    \n",
    "    length = len(ids)\n",
    "\n",
    "    for i in range(0, 512, batch_size):\n",
    "        if i == ((length // batch_size) * batch_size):\n",
    "            paths = img_paths[i:]\n",
    "            captions = img_captions[i:]\n",
    "            # text_embeds, text_masks = get_emb_tensor(captions)\n",
    "        else:\n",
    "            paths = img_paths[i:i+batch_size]\n",
    "            captions = img_captions[i:i+batch_size]\n",
    "            # text_embeds, text_masks = get_emb_tensor(captions)\n",
    "        for i in range(0, len(paths)):\n",
    "            img_path = paths[i]\n",
    "            embed_fp = train_embed_dir + img_path[:-4] + \"_embedding\" + \".npy\"\n",
    "            mask_fp = train_embed_dir + img_path[:-4] + \"_mask\" + \".npy\"\n",
    "            # np.save(id_, )\n",
    "            print(embed_fp, mask_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3865a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf376d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88d54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b3f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(root, id):\n",
    "    path = coco.loadImgs(id)[0][\"file_name\"]\n",
    "    return Image.open(os.path.join(root, path)).convert(\"RGB\")\n",
    "\n",
    "def load_target(root, id):\n",
    "    return coco.loadAnns(coco.getAnnIds(id))\n",
    "\n",
    "\n",
    "def precompute_embeddings(root, annFile):\n",
    "    # root = \"coco\\\\images\\\\train2014\"\n",
    "    \n",
    "    coco = COCO(annFile)\n",
    "    ids = list(sorted(coco.imgs.keys()))\n",
    "\n",
    "    # for id in ids\n",
    "    # ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d71aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b58c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
